{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data stations ordered\n",
    "\n",
    "### Purpose & Motivation\n",
    "\n",
    "The purpose of this notebook is to create geojson files for the Wiggle Visualization by consuming data that has been processed from databricks for years 2008 to 2015 for the 5 minute frame. Metadata is consolidated within this notebook since the files are small and can be processed locally quickly.\n",
    "\n",
    "Both the points geojson (for the markers) and the lines geojson (for the segments) is generated from this notebook.\n",
    "\n",
    "### Direction from Advisor\n",
    "\n",
    "N/A\n",
    "\n",
    "### Tasks/Questions to Answer\n",
    "#### Questions to Answer\n",
    "\n",
    "N/A\n",
    "\n",
    "#### Tasks\n",
    "\n",
    "Create a geojson file that is consumed by the visualization.\n",
    "\n",
    "### Results\n",
    "\n",
    "See below\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "import pandas as pd\n",
    "import simplejson\n",
    "import numpy as np\n",
    "import urllib\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Metadata File for 2008 to 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2008\u001b[m\u001b[m \u001b[34m2009\u001b[m\u001b[m \u001b[34m2010\u001b[m\u001b[m \u001b[34m2011\u001b[m\u001b[m \u001b[34m2012\u001b[m\u001b[m \u001b[34m2013\u001b[m\u001b[m \u001b[34m2014\u001b[m\u001b[m \u001b[34m2015\u001b[m\u001b[m \u001b[34m2016\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/meta/2008/d11/d11_text_meta_2007_09_21.txt', '../data/meta/2008/d11/d11_text_meta_2008_03_06.txt', '../data/meta/2008/d11/d11_text_meta_2008_04_15.txt', '../data/meta/2008/d11/d11_text_meta_2008_04_16.txt', '../data/meta/2008/d11/d11_text_meta_2008_04_18.txt']\n"
     ]
    }
   ],
   "source": [
    "meta_dir = '../data/meta/*/d11/*text_meta_*.txt'\n",
    "meta_files = glob.glob(meta_dir)\n",
    "meta_file_list = []\n",
    "for meta_file in meta_files:\n",
    "    date = str('_'.join(meta_file.split('_')[4:7])).split('.')[0]\n",
    "    df = pd.read_table(meta_file, index_col=None, header=0)\n",
    "    date_col = pd.Series([date] * len(df))\n",
    "    df['file_date'] = date_col\n",
    "    meta_file_list.append(df)\n",
    "    \n",
    "print meta_files[0:5]\n",
    "meta_frame = pd.concat(meta_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ID', u'Fwy', u'Dir', u'District', u'County', u'City', u'State_PM',\n",
       "       u'Abs_PM', u'Latitude', u'Longitude', u'Length', u'Type', u'Lanes',\n",
       "       u'Name', u'User_ID_1', u'User_ID_2', u'User_ID_3', u'User_ID_4',\n",
       "       u'file_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total stations: 1783\n",
      "distribution of stations per type: \n",
      "ML    979\n",
      "OR    344\n",
      "FR    263\n",
      "HV    106\n",
      "FF     81\n",
      "CH      7\n",
      "CD      3\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print \"total stations: %s\" % len(meta_frame.ID.unique())\n",
    "print \"distribution of stations per type: \"\n",
    "print meta_frame.drop_duplicates(subset='ID', keep='last').Type.value_counts()\n",
    "all_stations = meta_frame.ID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique count of stations: 1779\n",
      "\n",
      "distribution of Types of stations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ML    975\n",
       "OR    344\n",
       "FR    263\n",
       "HV    106\n",
       "FF     81\n",
       "CH      7\n",
       "CD      3\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the type in the meta data are just the detector types.  Need to analyze the \"change\" that cohort 1 referred to\n",
    "drop_na = meta_frame.dropna(axis=0, how='any', subset=['Latitude', 'Longitude'])\n",
    "no_dup_keep_last = drop_na.drop_duplicates(subset='ID', keep='last') # TODO: assuming meta and 5min agree on freeway type...check?\n",
    "print \"unique count of stations: %s\" % no_dup_keep_last.shape[0]\n",
    "\n",
    "print \"\\ndistribution of Types of stations\"\n",
    "no_dup_keep_last.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Fwy</th>\n",
       "      <th>Dir</th>\n",
       "      <th>District</th>\n",
       "      <th>County</th>\n",
       "      <th>City</th>\n",
       "      <th>State_PM</th>\n",
       "      <th>Abs_PM</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Length</th>\n",
       "      <th>Type</th>\n",
       "      <th>Lanes</th>\n",
       "      <th>Name</th>\n",
       "      <th>User_ID_1</th>\n",
       "      <th>User_ID_2</th>\n",
       "      <th>User_ID_3</th>\n",
       "      <th>User_ID_4</th>\n",
       "      <th>file_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1113328</td>\n",
       "      <td>125</td>\n",
       "      <td>N</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.96</td>\n",
       "      <td>28.863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000</td>\n",
       "      <td>ML</td>\n",
       "      <td>2</td>\n",
       "      <td>CONNECTOR TO WB 52</td>\n",
       "      <td>353.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1113336</td>\n",
       "      <td>125</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.96</td>\n",
       "      <td>28.863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000</td>\n",
       "      <td>ML</td>\n",
       "      <td>2</td>\n",
       "      <td>52 EB CON TO 125 SB</td>\n",
       "      <td>354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1114649</td>\n",
       "      <td>805</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>28.811</td>\n",
       "      <td>28.662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.651</td>\n",
       "      <td>ML</td>\n",
       "      <td>4</td>\n",
       "      <td>S/B AT JCT I-5</td>\n",
       "      <td>4045.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>1125383</td>\n",
       "      <td>52</td>\n",
       "      <td>W</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>70224.0</td>\n",
       "      <td>14.756</td>\n",
       "      <td>14.756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695</td>\n",
       "      <td>ML</td>\n",
       "      <td>2</td>\n",
       "      <td>52 WB from 125 Conn</td>\n",
       "      <td>43812.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12_17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Fwy Dir  District  County     City State_PM  Abs_PM  Latitude  \\\n",
       "650   1113328  125   N        11      73      NaN    29.96  28.863       NaN   \n",
       "652   1113336  125   S        11      73      NaN    29.96  28.863       NaN   \n",
       "767   1114649  805   S        11      73  66000.0   28.811  28.662       NaN   \n",
       "1324  1125383   52   W        11      73  70224.0   14.756  14.756       NaN   \n",
       "\n",
       "      Longitude  Length Type  Lanes                 Name  User_ID_1  \\\n",
       "650         NaN   5.000   ML      2   CONNECTOR TO WB 52      353.0   \n",
       "652         NaN   5.000   ML      2  52 EB CON TO 125 SB      354.0   \n",
       "767         NaN   0.651   ML      4       S/B AT JCT I-5     4045.0   \n",
       "1324        NaN   0.695   ML      2  52 WB from 125 Conn    43812.0   \n",
       "\n",
       "      User_ID_2  User_ID_3  User_ID_4 file_date  \n",
       "650         NaN        NaN        NaN     08_13  \n",
       "652         NaN        NaN        NaN     08_13  \n",
       "767         NaN        NaN        NaN     12_17  \n",
       "1324        NaN        NaN        NaN     12_17  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_ids = no_dup_keep_last.ID.unique()\n",
    "missing_ids = set(all_stations) - set(filter_ids)\n",
    "\n",
    "meta_frame[meta_frame.ID.isin(missing_ids)].drop_duplicates(subset='ID', keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of the stations above\n",
    "I reviewed the stations above and decided that they are ok to drop.\n",
    "The two stations for the 125 N / S are a lot higher on the Abs_PM then the end of the freeway, so even if it's valid it would mess up our analysis in that the next adjacent station is much further away than normal.\n",
    "\n",
    "For the 805 S station, it looks like there is another station are essentially the same location so this one will be ignored.\n",
    "28.811 \t28.66 \t0.197 \t1114649 \tS/B AT JCT I-5 \t4 \tMainline \tOther \tNo \t1114643 \t4045\n",
    "\n",
    "For the 52W it also looks like this station has been replaced.\n",
    "Santee \t14.756 \t14.76 \t0.695 \t1125383 \t52 WB from 125 Conn \t2 \tMainline \t\tNo \t1111463 \t43812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_dup_keep_last.to_csv('../data/meta_2008_2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ML', 'OR', 'FR', 'FF', 'HV', 'CD', 'CH'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_dup_keep_last.Type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_freeway_vectors(frame_to_use, columns_to_select=['ID', 'Latitude', 'Longitude', 'Abs_PM', 'Lanes']):\n",
    "    frame_to_use = frame_to_use[frame_to_use.Type == 'ML']\n",
    "    to_loop = frame_to_use.groupby(['Fwy', 'Dir'])['ID'].count().reset_index()[['Fwy', 'Dir']].values\n",
    "\n",
    "    ret = {}\n",
    "    for Fwy, Dir in to_loop:\n",
    "        if Dir == \"N\":\n",
    "            sort_order = ('Abs_PM', True)        \n",
    "        elif Dir == \"S\":\n",
    "            sort_order = ('Abs_PM', True)        \n",
    "        elif Dir == \"E\":\n",
    "            sort_order = ('Abs_PM', True)        \n",
    "        elif Dir == \"W\":\n",
    "            sort_order = ('Abs_PM', True)\n",
    "        \n",
    "        \n",
    "        tmp = frame_to_use[(frame_to_use.Fwy == Fwy) & (frame_to_use.Dir == Dir)]\\\n",
    "            .sort_values(by=sort_order[0], ascending=sort_order[1])[columns_to_select] # .drop_duplicates()\n",
    "        tmp['order'] = pd.Series(index=tmp.index, data=sorted(range(0, len(tmp.ID)), reverse=(not sort_order[1])))\n",
    "        ret[\"%s_%s\" % (Fwy, Dir)] = tmp\n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sorted_func(x):\n",
    "    values = x.split('_')\n",
    "    Fwy = int(values[0])\n",
    "    Dir = values[1]\n",
    "    if Dir == 'N' or Dir == 'E':\n",
    "        dir_weight = 0\n",
    "    else:\n",
    "        dir_weight = 1\n",
    "    return Fwy + dir_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freeway_vectors_update = create_freeway_vectors(\n",
    "    no_dup_keep_last, [u'ID', u'Fwy', u'Dir', u'Abs_PM', u'Latitude', u'Longitude', u'Lanes', u'Name', 'Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5_N',\n",
       " '5_S',\n",
       " '8_E',\n",
       " '8_W',\n",
       " '15_N',\n",
       " '15_S',\n",
       " '52_E',\n",
       " '52_W',\n",
       " '54_E',\n",
       " '54_W',\n",
       " '56_E',\n",
       " '56_W',\n",
       " '78_E',\n",
       " '78_W',\n",
       " '94_E',\n",
       " '94_W',\n",
       " '125_N',\n",
       " '125_S',\n",
       " '163_N',\n",
       " '163_S',\n",
       " '805_N',\n",
       " '805_S',\n",
       " '905_E',\n",
       " '905_W']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freeway_keys = sorted(freeway_vectors_update.keys(), key=sorted_func)\n",
    "freeway_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                        1114091\n",
      "Fwy                             5\n",
      "Dir                             N\n",
      "Abs_PM                      0.057\n",
      "Latitude                  32.5428\n",
      "Longitude                 -117.03\n",
      "Lanes                           6\n",
      "Name         N/O CMNO DE LA PLAZA\n",
      "Type                           ML\n",
      "order                           0\n",
      "Name: 730, dtype: object\n",
      "1114091\n"
     ]
    }
   ],
   "source": [
    "for ind, i in freeway_vectors_update['5_N'].iterrows():\n",
    "    print i\n",
    "    print i['ID']\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create geojson using 2008 through 2015 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data for all districts if decide to upscale\n",
    "# from pyspark.sql.functions import hour, mean,minute, stddev, count,max as psmax,min as psmin, date_format, \\\n",
    "#     split, explode\n",
    "\n",
    "# from pyspark.sql import SQLContext\n",
    "# from pyspark.sql import Row\n",
    "# from pyspark.sql.types import *\n",
    "# from pyspark.sql import DataFrameReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# spark_df = spark.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\") \\\n",
    "#     .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "#     .load('../data/stats_2008_2015_d11.csv');\n",
    "\n",
    "# spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'station', u'hour', u'minute', u'flow_mean'], dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv('../data/weekday_stats_2008_2015_d11.csv', usecols=range(1,5))\n",
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ID', u'Fwy', u'Dir', u'District', u'County', u'City', u'State_PM',\n",
       "       u'Abs_PM', u'Latitude', u'Longitude', u'Length', u'Type', u'Lanes',\n",
       "       u'Name', u'User_ID_1', u'User_ID_2', u'User_ID_3', u'User_ID_4',\n",
       "       u'file_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_dup_keep_last.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 94  78   5 805   8 163  15  52 125 905  56  54  67]\n"
     ]
    }
   ],
   "source": [
    "print no_dup_keep_last.Fwy.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'station', u'hour', u'minute', u'flow_mean'], dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new['Time'] = pd.to_datetime(df_new['hour'].astype('str') + ':' + df_new['minute'].astype('str'),\n",
    "                                format='%H:%M').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1100745, datetime.time(0, 0), 7.512630014860001],\n",
       "       [1108341, datetime.time(0, 0), 51.48754789270001],\n",
       "       [1118333, datetime.time(0, 0), 33.414307004499996],\n",
       "       ..., \n",
       "       [1122612, datetime.time(6, 35), nan],\n",
       "       [1118394, datetime.time(4, 35), 72.0],\n",
       "       [1118401, datetime.time(23, 0), 112.0]], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df_new[['station', 'Time', 'flow_mean']].as_matrix()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete_with_meta = pd.merge(df_new, no_dup_keep_last[['ID', 'District', 'County', 'City', 'State_PM', 'Abs_PM',\n",
    "                                                      'Latitude', 'Longitude', 'Name', 'Lanes', 'Type', 'Fwy',\n",
    "                                                      'Dir']], how='left', left_on='station',\n",
    "                              right_on='ID')\n",
    "complete_with_meta['Time'] = pd.to_datetime(complete_with_meta['hour'].astype('str') + ':' + \\\n",
    "                                            complete_with_meta['minute'].astype('str'),\n",
    "                                format='%H:%M').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_day = []\n",
    "for key in freeway_keys:\n",
    "    Fwy, Dir = key.split('_')\n",
    "    tmp = complete_with_meta[(complete_with_meta.Fwy == int(Fwy)) & (complete_with_meta.Dir == Dir)]\n",
    "    average_day.append(tmp.groupby('ID')['flow_mean'].mean())\n",
    "df_avg = pd.concat(average_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete_with_meta_avg = pd.merge(pd.DataFrame(df_avg).reset_index(),\n",
    "                                  no_dup_keep_last[['ID', 'District', 'County', 'City', 'State_PM', 'Abs_PM',\n",
    "                                                    'Latitude', 'Longitude', 'Name', 'Lanes', 'Type', 'Fwy',\n",
    "                                                    'Dir']], how='left', left_on='ID',\n",
    "                              right_on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ID', u'flow_mean', u'District', u'County', u'City', u'State_PM',\n",
       "       u'Abs_PM', u'Latitude', u'Longitude', u'Name', u'Lanes', u'Type',\n",
       "       u'Fwy', u'Dir'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_with_meta_avg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  94.,    8.,    5.,  805.,   15.,   78.,   52.,  163.,  125.,\n",
       "         56.,  905.,   54.,   nan,   67.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_with_meta.Fwy.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'station', u'hour', u'minute', u'flow_mean', u'Time'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ID', u'Fwy', u'Dir', u'Abs_PM', u'Latitude', u'Longitude', u'Lanes',\n",
       "       u'Name', u'Type', u'order'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freeway_vectors_update[key].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_N\n",
      "geojson len: 135\n",
      "5_S\n",
      "geojson len: 119\n",
      "8_E\n",
      "geojson len: 49\n",
      "8_W\n",
      "geojson len: 49\n",
      "15_N\n",
      "geojson len: 87\n",
      "15_S\n",
      "geojson len: 84\n",
      "52_E\n",
      "geojson len: 27\n",
      "52_W\n",
      "geojson len: 28\n",
      "54_E\n",
      "geojson len: 3\n",
      "54_W\n",
      "geojson len: 3\n",
      "56_E\n",
      "geojson len: 17\n",
      "56_W\n",
      "geojson len: 14\n",
      "78_E\n",
      "geojson len: 19\n",
      "78_W\n",
      "geojson len: 26\n",
      "94_E\n",
      "geojson len: 16\n",
      "94_W\n",
      "geojson len: 23\n",
      "125_N\n",
      "geojson len: 35\n",
      "125_S\n",
      "geojson len: 37\n",
      "163_N\n",
      "geojson len: 15\n",
      "163_S\n",
      "geojson len: 17\n",
      "805_N\n",
      "geojson len: 73\n",
      "805_S\n",
      "geojson len: 75\n",
      "905_E\n",
      "geojson len: 11\n",
      "905_W\n",
      "geojson len: 13\n"
     ]
    }
   ],
   "source": [
    "# update ML file for 2008 to 2015\n",
    "final = {}\n",
    "\n",
    "for key in freeway_keys:\n",
    "    print key\n",
    "    new_geojson = {'type': 'FeatureCollection', 'features': []}\n",
    "\n",
    "    # freeway_vectors_update has all of the metadata info\n",
    "    df = freeway_vectors_update[key]\n",
    "    for idx, row in df.iterrows():\n",
    "        properties = {'key': key,\n",
    "                      'ID': row['ID'],\n",
    "                      'Lanes': row['Lanes'],\n",
    "                      'Name': row['Name'],\n",
    "                      'Abs_PM': np.round(row['Abs_PM'], decimals=1),\n",
    "                      'Order': row['order'],\n",
    "                      'Type': row['Type'],\n",
    "                     }\n",
    "        flow_data = df_new[df_new.station == row['ID']][['Time', 'flow_mean']].sort_values(by='Time').set_index('Time')\n",
    "        properties['Flow'] = flow_data.flow_mean.tolist()\n",
    "        geometry = {'type': \"Point\", \"coordinates\": [row['Longitude'], row['Latitude']]}\n",
    "        temp = {'type': 'Feature', 'properties': properties, \"geometry\": geometry}\n",
    "        new_geojson['features'].append(temp)\n",
    "#         break\n",
    "    print \"geojson len: %s\" % len(new_geojson['features'])\n",
    "    final[key] = {'visible': False, 'data': new_geojson}\n",
    "#     print final\n",
    "#     break\n",
    "\n",
    "json_string = json.dumps(final)\n",
    "final_string = 'var meta_data_points = ' + json_string\n",
    "with open('../vis/WiggleVis/data/2015_to_2008_ML_d11_geojson_points2.js', 'w') as outfile:\n",
    "    outfile.write(final_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculate midpoint\n",
    "\n",
    "source: http://www.movable-type.co.uk/scripts/latlong.html\n",
    "\n",
    "var Bx = Math.cos(φ2) * Math.cos(λ2-λ1);\n",
    "\n",
    "var By = Math.cos(φ2) * Math.sin(λ2-λ1);\n",
    "\n",
    "var φ3 = Math.atan2(Math.sin(φ1) + Math.sin(φ2),\n",
    "                    Math.sqrt( (Math.cos(φ1)+Bx)*(Math.cos(φ1)+Bx) + By*By ) );\n",
    "\n",
    "var λ3 = λ1 + Math.atan2(By, Math.cos(φ1) + Bx);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source:\n",
    "# http://stackoverflow.com/questions/5895832/python-lat-long-midpoint-calculation-gives-wrong-result-when-longitude-90\n",
    "import math\n",
    "\n",
    "def midpoint(lat1, lon1, lat2, lon2, debug=False):\n",
    "    if debug:\n",
    "        print lat1, lon1\n",
    "        print lat2, lon2\n",
    "    lonA = math.radians(lon1)\n",
    "    lonB = math.radians(lon2)\n",
    "    latA = math.radians(lat1)\n",
    "    latB = math.radians(lat2)\n",
    "\n",
    "    dLon = lonB - lonA\n",
    "\n",
    "    Bx = math.cos(latB) * math.cos(dLon)\n",
    "    By = math.cos(latB) * math.sin(dLon)\n",
    "\n",
    "    latC = math.atan2(math.sin(latA) + math.sin(latB),\n",
    "                  math.sqrt((math.cos(latA) + Bx) * (math.cos(latA) + Bx) + By * By))\n",
    "    lonC = lonA + math.atan2(By, math.cos(latA) + Bx)\n",
    "    lonC = (lonC + 3 * math.pi) % (2 * math.pi) - math.pi\n",
    "\n",
    "    return math.degrees(latC), math.degrees(lonC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.54726623446039, -117.03802762069233)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "midpoint(32.542842, -117.030331, 32.551690, -117.045725)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 135\n"
     ]
    }
   ],
   "source": [
    "# prototype\n",
    "# shifted = freeway_vectors_update['5_N'].shift(-1)\n",
    "# result = []\n",
    "# final = []\n",
    "# total = len(freeway_vectors_update['5_N'])\n",
    "# print \"total: %s\" % total\n",
    "# index = 0\n",
    "# for idx, item in freeway_vectors_update['5_N'].iterrows():\n",
    "# #     print item['order']\n",
    "# #     print index\n",
    "#     if item['order'] != (total - 1):\n",
    "#         result.append(midpoint(item['Latitude'], item['Longitude'], shifted.iloc[index]['Latitude'],\n",
    "#                                shifted.iloc[index]['Longitude']))\n",
    "#         final.append([item['Latitude'], item['Longitude'], result[index][0], result[index][1]])\n",
    "#     else:\n",
    "#         final.append([result[index-1][0], result[index-1][1], item['Latitude'], item['Longitude']])\n",
    "#     index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geometry': {'coordinates': [[11.836395263671875, 47.75317468890147],\n",
       "   [11.865234375, 47.73193447949174]],\n",
       "  'type': 'LineString'},\n",
       " 'properties': {'elevation': 50, 'id': 2},\n",
       " 'type': 'Feature'}"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example format for geojson for the line\n",
    "{ \n",
    "    \"type\": \"Feature\",\n",
    "    \"properties\":\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"elevation\": 50\n",
    "    },\n",
    "    \"geometry\":\n",
    "    {\n",
    "        \"type\": \"LineString\",\n",
    "        \"coordinates\": \n",
    "        [\n",
    "            [ 11.836395263671875, 47.75317468890147 ],\n",
    "            [ 11.865234375, 47.73193447949174 ]\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example of format\n",
    "# [ \n",
    "# { \"type\": \"Feature\", \"properties\": { \"id\": 2, \"elevation\": 50 }, \"geometry\": { \"type\": \"LineString\", \"coordinates\": [ [ 11.836395263671875, 47.75317468890147 ], [ 11.865234375, 47.73193447949174 ] ] } },\n",
    "# { \"type\": \"Feature\", \"properties\": { \"id\": 1, \"elevation\": 750 }, \"geometry\": { \"type\": \"LineString\", \"coordinates\": [ [ 11.865234375,47.73193447949174 ], [ 11.881027221679688, 47.700520033704954 ] ] } },\n",
    "# { \"type\": \"Feature\", \"properties\": { \"id\": 0, \"elevation\": 1700 }, \"geometry\": { \"type\": \"LineString\", \"coordinates\": [ [ 11.881027221679688, 47.700520033704954 ], [ 11.923599243164062, 47.706527200903395 ] ] } },\n",
    "# { \"type\": \"Feature\", \"properties\": { \"id\": 0, \"elevation\": 3000 }, \"geometry\": { \"type\": \"LineString\", \"coordinates\": [ [ 11.923599243164062, 47.706527200903395 ], [ 11.881027221679688, 47.700520033704954 ], ] } }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_segments(freeway_df, wig_dat):\n",
    "    \"\"\"\n",
    "    This function will calculate the segments from the ordered stations and return\n",
    "    an array of midpoints\n",
    "    \"\"\"\n",
    "    shifted = freeway_df.shift(-1)\n",
    "    result = []\n",
    "    final = []\n",
    "    data = []\n",
    "    stations = []\n",
    "    total = len(freeway_df)\n",
    "    print \"total: %s\" % total\n",
    "    index = 0\n",
    "    for idx, item in freeway_df.iterrows():\n",
    "    #     print item['order']\n",
    "    #     print index\n",
    "#         print item\n",
    "        station = item['ID']\n",
    "        stations.append(station)\n",
    "        points = wig_dat[wig_dat.ID == station].reset_index().T.iloc[2:1442].T.ix[0].tolist()\n",
    "#         print points\n",
    "        data.append(points)\n",
    "        if item['order'] == 0:\n",
    "            result.append(midpoint(item['Latitude'], item['Longitude'], shifted.iloc[index]['Latitude'],\n",
    "                                   shifted.iloc[index]['Longitude']))\n",
    "            final.append((1, [[item['Longitude'], item['Latitude']], [result[index][1], result[index][0]]]))\n",
    "        elif item['order'] != (total - 1):\n",
    "            result.append(midpoint(item['Latitude'], item['Longitude'], shifted.iloc[index]['Latitude'],\n",
    "                                   shifted.iloc[index]['Longitude']))\n",
    "            final.append((2, [[result[index-1][1], result[index-1][0]], [item['Longitude'], item['Latitude']]],\n",
    "                         [[item['Longitude'], item['Latitude']], [result[index][1], result[index][0]]]))\n",
    "        else:\n",
    "            final.append((1, [[result[index-1][1], result[index-1][0]], [item['Longitude'], item['Latitude']]]))\n",
    "        index += 1\n",
    "    return final, data, stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 135\n"
     ]
    }
   ],
   "source": [
    "example = pd.read_csv('../vis/WiggleVis/data/heatmaps/wiggle_analysis_%s_%s.csv' % (5, 'N'))\n",
    "# print example.head()\n",
    "segments, wiggles, stations = calculate_segments(freeway_vectors_update['5_N'], example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "segments\n",
    "print idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_N\n",
      "total: 135\n",
      "5_S\n",
      "total: 119\n",
      "8_E\n",
      "total: 49\n",
      "8_W\n",
      "total: 49\n",
      "15_N\n",
      "total: 87\n",
      "15_S\n",
      "total: 84\n",
      "52_E\n",
      "total: 27\n",
      "52_W\n",
      "total: 28\n",
      "54_E\n",
      "total: 3\n",
      "54_W\n",
      "total: 3\n",
      "56_E\n",
      "total: 17\n",
      "56_W\n",
      "total: 14\n",
      "78_E\n",
      "total: 19\n",
      "78_W\n",
      "total: 26\n",
      "94_E\n",
      "total: 16\n",
      "94_W\n",
      "total: 23\n",
      "125_N\n",
      "total: 35\n",
      "125_S\n",
      "total: 37\n",
      "163_N\n",
      "total: 15\n",
      "163_S\n",
      "total: 17\n",
      "805_N\n",
      "total: 73\n",
      "805_S\n",
      "total: 75\n",
      "905_E\n",
      "total: 11\n",
      "905_W\n",
      "total: 13\n"
     ]
    }
   ],
   "source": [
    "# update ML file for 2008 to 2015\n",
    "final = {}\n",
    "\n",
    "for key in freeway_keys:\n",
    "# for key in ['54_W']:\n",
    "    print key\n",
    "    Fwy, Dir = key.split('_')\n",
    "    wiggle_data = pd.read_csv('../vis/WiggleVis/data/heatmaps/wiggle_analysis_%s_%s.csv' % (Fwy, Dir))\n",
    "    segments, wiggles, stations = calculate_segments(freeway_vectors_update[key], wiggle_data)\n",
    "\n",
    "    data_to_store = {'type': \"FeatureCollection\", 'features': []}\n",
    "    for segs, wig, stat in zip(segments, wiggles, stations):\n",
    "#         print \"segs: %s\" % str(segs)\n",
    "        for idx in range(1, segs[0]+1):\n",
    "#             print idx\n",
    "#             print \"segs[idx]: %s\" % segs[idx]\n",
    "            new_geojson = {'type': 'Feature'}\n",
    "            properties = {'wiggles': wig, 'ID': stat}\n",
    "            geometry = {'type': \"LineString\", \"coordinates\": segs[idx]}\n",
    "            new_geojson['geometry'] = geometry\n",
    "            new_geojson['properties'] = properties\n",
    "    #         print new_geojson\n",
    "            data_to_store['features'].append(new_geojson)\n",
    "    final[key] = data_to_store\n",
    "#     pprint(final)\n",
    "# print final\n",
    "json_string = json.dumps(final)\n",
    "final_string = 'var segment_data = ' + json_string\n",
    "with open('../vis/WiggleVis/data/2015_to_2008_ML_d11_geojson_lines.js', 'w') as outfile:\n",
    "    outfile.write(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
